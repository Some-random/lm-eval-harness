{
  "results": {
    "mt_bench_discriminate_flan_t5_xxl": {
      "exact_match,remove_whitespace": 0.3625,
      "exact_match_stderr,remove_whitespace": 0.038123743406448904,
      "alias": "mt_bench_discriminate_flan_t5_xxl"
    }
  },
  "configs": {
    "mt_bench_discriminate_flan_t5_xxl": {
      "task": "mt_bench_discriminate_flan_t5_xxl",
      "dataset_path": "json",
      "dataset_kwargs": {
        "data_files": {
          "validation": "/bask/projects/j/jlxi8926-auto-sum/dongwei/FastChat/fastchat/llm_judge/mt_bench_flan_t5_xxl_evaluative.jsonl"
        }
      },
      "validation_split": "validation",
      "process_docs": "<function process_docs at 0x7f421cb1fa30>",
      "doc_to_text": "You will be given two LLM responses to a question. Please choose one answer from those answers that you think is the best answer to the question. Your final selection should be 1 or 2, where 1 represents the answer you choose is answer 1, 2 represents the answer you choose is answer 2. Please end your generation with 1 or 2\nHere are the two lists of answer choices.\nAnswer1: {{answer1}}\nAnswer2: {{answer2}}\nAnswer:",
      "doc_to_target": "{{choice}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "exact_match",
          "aggregation": "mean",
          "higher_is_better": true,
          "ignore_case": true,
          "ignore_punctuation": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "\n",
          ".",
          ","
        ],
        "do_sample": false,
        "temperature": 0.0
      },
      "repeats": 1,
      "filter_list": [
        {
          "name": "remove_whitespace",
          "filter": [
            {
              "function": "remove_whitespace"
            },
            {
              "function": "take_first"
            }
          ]
        }
      ],
      "should_decontaminate": false,
      "metadata": {
        "version": 3.0
      }
    }
  },
  "versions": {
    "mt_bench_discriminate_flan_t5_xxl": 3.0
  },
  "n-shot": {
    "mt_bench_discriminate_flan_t5_xxl": 5
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=google/flan-t5-xxl",
    "batch_size": "3",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null
  },
  "git_hash": "90c92fe"
}